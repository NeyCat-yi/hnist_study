## TensorBoard

安装：pip install tensorboard

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter  # <--- 1. 导入

# ==========================================
# 2. 初始化 Writer
# ==========================================
# 'runs/resnet_experiment_1' 是日志保存的文件夹路径
# 每次改这个名字（比如 experiment_2），就可以在网页上对比两次训练的结果
writer = SummaryWriter('runs/resnet_experiment_1')

# 假设模型和数据加载器已经准备好
# model = ...
# train_loader = ...
# optimizer = ...
# criterion = ...

num_epochs = 10

# 定义一个全局步数，用于记录这是第几个 Batch
global_step = 0

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)
        
        # 前向 + 反向 + 优化
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        # ==========================================
        # 3. 记录 Loss (每个 Batch 记一次，画图更细致)
        # ==========================================
        # tag: 图表的标题 ('Train/Loss')
        # scalar_value: y轴的值 (当前 Loss)
        # global_step: x轴的值 (当前步数)
        writer.add_scalar('Train/Loss', loss.item(), global_step)
        
        global_step += 1

    # ==========================================
    # 4. (可选) 记录每个 Epoch 的准确率
    # ==========================================
    # 假设你这里算出验证集准确率 val_acc
    # writer.add_scalar('Val/Accuracy', val_acc, epoch)
    
    print(f"Epoch {epoch+1} 完成")

# ==========================================
# 5. 训练结束关闭 Writer
# ==========================================
writer.close()
```



## 读取图片

###  一、用 **PIL (Pillow)** —— 最通用、最常配合 PyTorch 用



```python
from PIL import Image

img_path = r"D:\path\to\image.jpg"
img = Image.open(img_path).convert('RGB')   # 读入并转为三通道RGB
img.show()                                  # 显示图片
print(type(img), img.size)                  # <class 'PIL.Image.Image'>, (宽, 高)

```

### 二、用 **torchvision.io.read_image()** —— 直接读成 Tensor

```python
from torchvision.io import read_image

img_path = r"D:\path\to\image.jpg"
img = read_image(img_path)      # Tensor [C,H,W], dtype=uint8, 值∈[0,255]
print(img.shape)                # 例如 torch.Size([3, 224, 224])

```

### 三、用 **OpenCV (cv2)** —— 图像处理、计算机视觉常用

```python
import cv2

img_path = r"D:\path\to\image.jpg"
img = cv2.imread(img_path)      # ndarray, BGR顺序
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # 转成RGB
cv2.imshow('Image', img)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### 四、用 **matplotlib.pyplot.imread()** —— 轻量可视化

```python
import matplotlib.pyplot as plt

img_path = r"D:\path\to\image.jpg"
img = plt.imread(img_path)      # numpy 数组 [H,W,3], 值通常在 [0,1]
plt.imshow(img)
plt.axis('off')
plt.show()

```

## 读取数据集与dataloader

### 1、pandas + scikit-learn

```python
import pandas as pd # pip install pandas
from sklearn.model_selection import train_test_split # pip install scikit-learn
# 1. 读取 CSV 文件
# 请将 'your_data.csv' 替换为你真实的文件名
df = pd.read_csv('datasets/origin.csv')

# 2. 使用 sklearn 进行拆分
# test_size=0.2  -> 表示测试集占 20%，训练集自动占 80%
# random_state=42 -> 随机种子，确保每次运行代码切分的结果都一样（可换成任意数字）
# shuffle=True   -> 默认就是 True，表示会先随机打乱数据再切分
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)

# 3. 保存文件
# index=False 表示不保存索引列（通常你需要这样设置）
train_df.to_csv('datasets/train_data.csv', index=False)
test_df.to_csv('datasets/test_data.csv', index=False)
```

*定义自定义 Dataset 类 和 dataloader*

```python
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd

# --- 1. 定义自定义 Dataset 类 ---
class CSVDataset(Dataset):
    def __init__(self, dataframe, target_column=None):
        """
        dataframe: 传入 pandas dataframe (例如 train_df)
        target_column: 目标值(标签)的列名。
                       如果有这个参数，返回 (features, label)
                       如果没有，只返回 features (用于预测)
        """
        # 提取数据
        if target_column:
            # 分离特征 (X) 和 标签 (y)
            # drop 掉标签列，剩下的都是特征
            self.X = dataframe.drop(columns=[target_column]).values
            self.y = dataframe[target_column].values
            self.has_target = True
        else:
            self.X = dataframe.values
            self.has_target = False

        # 转换为 PyTorch Tensor
        # 注意：通常特征使用 float32
        self.X = torch.tensor(self.X, dtype=torch.float32)
        
        if self.has_target:
            # 如果是分类任务(0,1,2...)通常用 long，回归任务用 float32
            # 这里默认转为 float32，如果是分类任务请改成 torch.long
            self.y = torch.tensor(self.y, dtype=torch.float32)

    def __len__(self):
        # 返回数据总长度
        return len(self.X)

    def __getitem__(self, idx):
        # 根据索引 idx 返回一条数据
        if self.has_target:
            return self.X[idx], self.y[idx]
        else:
            return self.X[idx]

# --- 2. 模拟使用流程 (接你上一步的代码) ---

# 假设这是你刚才切分好的数据
# 为了演示，我先造一个假的 dataframe
data = {
    'feature1': [0.1, 0.2, 0.3, 0.4, 0.5],
    'feature2': [1.1, 1.2, 1.3, 1.4, 1.5],
    'label':    [0,   1,   0,   1,   0]    # 假设 'label' 是我们要预测的目标列
}
train_df = pd.DataFrame(data)

# >>> 关键步骤开始 <<<

# A. 实例化 Dataset
# 你需要把 'label' 换成你 CSV 里真实的标签列名（比如 'price', 'category' 等）
train_dataset = CSVDataset(train_df, target_column='label')

# B. 实例化 DataLoader
# batch_size=2: 每次吐出 2 条数据
# shuffle=True: 每个 epoch 都会重新打乱数据（训练集通常需要 True）
train_loader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)

# --- 3. 测试一下 DataLoader ---
print("开始读取 Batch 数据:")
for batch_idx, (features, labels) in enumerate(train_loader):
    print(f"\nBatch {batch_idx + 1}:")
    print(f"特征 Tensor 形状: {features.shape}")
    print(f"标签 Tensor 形状: {labels.shape}")
    print("特征数据:", features)
    print("标签数据:", labels)
```

