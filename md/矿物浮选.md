# VideoMAE 框架图说明

![框架图](resources\a8f14e96-7bf4-4f49-bf3f-9ef7c4027e15.png)

1. **总体结构**  
   采用不对称的 **Encoder–Decoder** 进行自监督重建：对视频立方体随机大比例遮挡（tube masking），再用解码器在像素空间复原被遮挡区域。

2. **高掩蔽率的 时间管状掩蔽（Tube Masking）**  
   在整条时间轴共享同一遮挡图（tube），掩蔽率极高（约 **90–95%**），仅保留少量可见 token 进入编码器，增强任务难度并抑制相邻帧信息泄露。

3. **时序采样与剪辑**  
   从原视频随机取一段连续 clip，按步长 **τ** 做时间下采样得到 **T** 帧（论文常用：Kinetics τ=4、SSV2 τ=2），单帧大小为 **H×W×3**。

4. **立方体贴片嵌入（Cube Embedding）**  
   将视频分块为 **2×16×16**（示例）这样的时空立方体作为一个 token，联合编码时空维度以降低冗余。

5. **编码器（Encoder）**  
   主干为 **vanilla ViT**，采用 **联合时空注意力（joint space–time attention）**；只接收未被遮挡的 token（约 5–10%），计算开销显著降低。

6. **解码器（Decoder）**  
   结构相对浅，加入**可学习的 mask token** 补齐被遮挡位置；在**像素空间**仅对**被遮挡的立方体**做重建，输出再 **reshape** 回帧序列（如 **3×T×H×W**）。

7. **训练目标（Reconstruction Target）**  
   对归一化后的立方体像素进行重建回归，不引入额外的预文本或语义标签。

