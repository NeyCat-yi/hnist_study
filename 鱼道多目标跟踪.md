# 鱼道多目标跟踪

**技术：yolo11 + BoT-SORT**

先检测后跟踪

**BoT-SORT结构**：

![image-20250717205148759](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250717205148759.png)

视频帧被检测之后分为低分和高分检测框，同时，视频帧在经过相机运动补偿后和上一帧视频帧一起被卡尔曼滤波器预测一下bounding boxs. 

检测高分 bounding boxs 和卡尔曼滤波器预测的 bounding boxs 进行第一次匹配(匈牙利匹配)

检测低分 bounding boxs 和第一次匹配未匹配上的 bounding boxs 做第二次匹配

## 改进点：

1. **卡尔曼滤波器**：

   使用离散卡尔曼滤波器来建模图像平面中物体的运动，采用常速度模型，使用**更准确的状态向量**

2. **相机运动补偿**

   通过**相机运动补偿**来纠正相机运动对目标跟踪的影响，提高跟踪的准确性

3. **IoU和ReID的余弦距离融合**

   提出了一种新的简单但有效的方法，用于**IoU和ReID的余弦距离融合**，以更稳健地关联检测和轨迹

   ![image-20250718150550377](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250718150550377.png)

关联匹配中代价矩阵由以上公式得出

diou 是第 i 个bounding boxs 和 第 j 个bounding boxs 之间的 IoU 距离，表示运动成本

dcos 是平均 tracklet 特征描述 i 和 新外观描述 j 之间的余弦距离

若是 上面两个距离都小于各自的阈值，成本减半 否则为 1（同时关注IoU距离和 特征相似度）

## 工作：

**收集鱼道数据**

**视频去除畸变**

**打标签**

![image-20250718171439842](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250718171439842.png)

![image-20250718172347583](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250718172347583.png)

第一次训练精度不高，标签分布也不均衡，中部识别能力弱

优化数据集后模型能力得到显著提升

![image-20250718172833180](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250718172833180.png)

![image-20250718171239412](C:\Users\34356\AppData\Roaming\Typora\typora-user-images\image-20250718171239412.png)

一共887帧，709帧训练集，88帧验证集，90帧测试集

**训练检测模型**

**调整参数**

**加入小目标层**

**研究改进方法**

检测框基本能识别出来，根据BoT-SORT 算法中的匹配逻辑（同时关注IoU和 特征相似度）推测是 深度外观提取器那一步没做好 也就是特征学的不好

尝试更新硬件得到更高分辨率的数据

尝试训练一个 更大的特征提取器

尝试制作多尺度数据集

网上有人做相似的工作，尝试运用他人的数据标注方法看是否能进一步提升检测精度





